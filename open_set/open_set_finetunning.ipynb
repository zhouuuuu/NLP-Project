{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"131MQ3N4oimPh1cM3LMBHNpjhiA_zDlPi","authorship_tag":"ABX9TyN1QBvjaLyHR8NcIjTHcE8J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"36c7b1e4f0c541f6b6f4c53d62195fcc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_075dd65d3560482eae295ab5dea1574b","IPY_MODEL_def53e9b690f404892abdea7e7c5db7f","IPY_MODEL_6d889daedf2b49e8879a7c7c361b7fde"],"layout":"IPY_MODEL_84d2c278f204450e935b7152c996f759"}},"075dd65d3560482eae295ab5dea1574b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdd27e5aaf334df2a94001e70af9a1c8","placeholder":"​","style":"IPY_MODEL_25ab19c9eb5f4986972217c16bd209ae","value":"config.json: 100%"}},"def53e9b690f404892abdea7e7c5db7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ccc19bb72104083b1e6426c0ae1b56f","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c61ea5dd4b97425cb15e9512e39e8f55","value":580}},"6d889daedf2b49e8879a7c7c361b7fde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f6b244405124b0db475645195fd25b7","placeholder":"​","style":"IPY_MODEL_e7fc93c0aa054f8ea7f13984b8056390","value":" 580/580 [00:00&lt;00:00, 56.5kB/s]"}},"84d2c278f204450e935b7152c996f759":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdd27e5aaf334df2a94001e70af9a1c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25ab19c9eb5f4986972217c16bd209ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ccc19bb72104083b1e6426c0ae1b56f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c61ea5dd4b97425cb15e9512e39e8f55":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f6b244405124b0db475645195fd25b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7fc93c0aa054f8ea7f13984b8056390":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55b786d0367e428ca17fdf35c8404f82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4aea7fd0d5f4483a7164bedc29c06ee","IPY_MODEL_730247ae3ce74279b1d08f8e10fe209d","IPY_MODEL_87094fbd7e49426d8e66bc6115f20fe3"],"layout":"IPY_MODEL_9d89a156368045bc801602c471a95b18"}},"c4aea7fd0d5f4483a7164bedc29c06ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e44b5e353f834c688db4be4bcaea1cca","placeholder":"​","style":"IPY_MODEL_b0faf9300cfe44ffaaad5e3b97cc31f8","value":"pytorch_model.bin: 100%"}},"730247ae3ce74279b1d08f8e10fe209d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d0eab6a57db4d96988b5403f40f7bc7","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7aeb345648e34410bf0bbd35c966ea6f","value":873673253}},"87094fbd7e49426d8e66bc6115f20fe3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_707ce628f2ae4769814404fdcd5b122e","placeholder":"​","style":"IPY_MODEL_c02894a658de4a86bfc9184e3444f90f","value":" 874M/874M [00:04&lt;00:00, 281MB/s]"}},"9d89a156368045bc801602c471a95b18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e44b5e353f834c688db4be4bcaea1cca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0faf9300cfe44ffaaad5e3b97cc31f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d0eab6a57db4d96988b5403f40f7bc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aeb345648e34410bf0bbd35c966ea6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"707ce628f2ae4769814404fdcd5b122e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c02894a658de4a86bfc9184e3444f90f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"301fbbb772e248438617a76121a2a4a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45371e99eab54e8aa9ad2dde28ba5484","IPY_MODEL_72067b3fe6a441958c4629202c2a5f4a","IPY_MODEL_63c8ac95f7ee47549e5a5e1a37cd502c"],"layout":"IPY_MODEL_7fc14670185848c9b01cce353a05cf3d"}},"45371e99eab54e8aa9ad2dde28ba5484":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13fc0273e88e4915be5bc48282d8a6d8","placeholder":"​","style":"IPY_MODEL_e5b32be19f814dde992b767650b8e2c2","value":"model.safetensors: 100%"}},"72067b3fe6a441958c4629202c2a5f4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95b800bd2ccf4dd480e016c9d0756339","max":873587410,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8337979b4eb40fbbbeedca626aa3720","value":873587410}},"63c8ac95f7ee47549e5a5e1a37cd502c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3477c7be06c40e98291771874f7217e","placeholder":"​","style":"IPY_MODEL_da563ee0ac5843c98bfc57601763139f","value":" 874M/874M [00:05&lt;00:00, 184MB/s]"}},"7fc14670185848c9b01cce353a05cf3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13fc0273e88e4915be5bc48282d8a6d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5b32be19f814dde992b767650b8e2c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95b800bd2ccf4dd480e016c9d0756339":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8337979b4eb40fbbbeedca626aa3720":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3477c7be06c40e98291771874f7217e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da563ee0ac5843c98bfc57601763139f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"033e9b17f9d045d1ba878323578824dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a049b3e8cd74ee08715dc55041aa5ca","IPY_MODEL_7471ad57a068481db3f50c926d198d1d","IPY_MODEL_6d9c400884f9451ebe297e9d742eb860"],"layout":"IPY_MODEL_e0dbac742b844023894e8967b7b06ac1"}},"9a049b3e8cd74ee08715dc55041aa5ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_868739e3aa804b0c99c6bae6ed7482c3","placeholder":"​","style":"IPY_MODEL_e04c652574d24609b84ef5c8c22d13a8","value":"tokenizer_config.json: 100%"}},"7471ad57a068481db3f50c926d198d1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bcaa7dc520f49bea97c1c2382114fcb","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b60fcc412dc141b6bdc60e530b969330","value":52}},"6d9c400884f9451ebe297e9d742eb860":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbe54986c9a544daa94763301f30966c","placeholder":"​","style":"IPY_MODEL_698aa626932a4a398d1ee5c092998b4f","value":" 52.0/52.0 [00:00&lt;00:00, 1.37kB/s]"}},"e0dbac742b844023894e8967b7b06ac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"868739e3aa804b0c99c6bae6ed7482c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e04c652574d24609b84ef5c8c22d13a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bcaa7dc520f49bea97c1c2382114fcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b60fcc412dc141b6bdc60e530b969330":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbe54986c9a544daa94763301f30966c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"698aa626932a4a398d1ee5c092998b4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4060425f40bb42099dbcea9c9bbf5c49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7342787d6cc4fb9918ad490197b9957","IPY_MODEL_037022f881e0485b9004c2707e0d7f30","IPY_MODEL_1add9a35d2784ad8b84fa8a9dcb18346"],"layout":"IPY_MODEL_36c376e1f74440b288373896db0da9f3"}},"c7342787d6cc4fb9918ad490197b9957":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7fad649420e479898b7ab538afcf761","placeholder":"​","style":"IPY_MODEL_e28c5910c870496284956025a07cfcd9","value":"spm.model: 100%"}},"037022f881e0485b9004c2707e0d7f30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef084790e9754569b968c86c77ed3381","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da8826d22f664deca028fe6e41fcd8df","value":2464616}},"1add9a35d2784ad8b84fa8a9dcb18346":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5433b88159654d0190235872c691f60e","placeholder":"​","style":"IPY_MODEL_304e68bfade34dbb8b0f029c6c6ee3a2","value":" 2.46M/2.46M [00:00&lt;00:00, 11.8MB/s]"}},"36c376e1f74440b288373896db0da9f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7fad649420e479898b7ab538afcf761":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e28c5910c870496284956025a07cfcd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef084790e9754569b968c86c77ed3381":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da8826d22f664deca028fe6e41fcd8df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5433b88159654d0190235872c691f60e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"304e68bfade34dbb8b0f029c6c6ee3a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# # 1. 安装所有必需的库\n","# !pip install torch transformers scikit-learn umap-learn matplotlib pandas seaborn"],"metadata":{"id":"h_zyR5OtmUMn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. 挂载 Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 3. 更改 Colab 的当前工作目录 (CWD)\n","# !!! 请确保这个路径与您截图中的 Google Drive 路径一致 !!!\n","%cd /content/drive/MyDrive/NLP/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4V_4g9Smasz","executionInfo":{"status":"ok","timestamp":1762355643463,"user_tz":-480,"elapsed":22005,"user":{"displayName":"flower","userId":"16750654610954148483"}},"outputId":"96a7ef7b-4eb9-4672-9708-94baf5c226a2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/NLP\n"]}]},{"cell_type":"code","source":["#!/usr/bin/env python3\n","\"\"\"\n","analyze_open_set.py\n","\n","为成员 D 实现的完整脚本：\n","- 加载 checkpoints/authorship_model.pt\n","- 提取 logits & embeddings\n","- 计算三类开集分数（max-prob, energy, prototype distance）\n","- 绘制 ROC / PR 曲线并寻找最佳阈值 tau（若有验证集）\n","- UMAP / t-SNE 可视化作者嵌入\n","- 导出错误样本分析 CSV\n","\n","依赖:\n","pip install torch transformers scikit-learn umap-learn matplotlib pandas seaborn\n","\"\"\"\n","import os\n","import argparse\n","import json\n","from typing import Tuple, Dict, List\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import AutoTokenizer, AutoModel\n","from sklearn.metrics import roc_curve, precision_recall_curve, auc, f1_score, classification_report\n","from sklearn.manifold import TSNE\n","import umap\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","\n","# --------------------------\n","# Config / Defaults\n","# --------------------------\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"设备检测: {DEVICE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0blpQ50HmcR8","executionInfo":{"status":"ok","timestamp":1762355716239,"user_tz":-480,"elapsed":70340,"user":{"displayName":"flower","userId":"16750654610954148483"}},"outputId":"a4d5ebc2-b115-497c-d031-8463cc2a69df"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["设备检测: cuda\n"]}]},{"cell_type":"code","source":["# --------------------------\n","# 1. 最小数据集和模型定义 (与 train.py 对齐)\n","# --------------------------\n","\n","class AuthorDataset(Dataset):\n","    \"\"\"\n","    自定义数据集类，用于加载作者文本。\n","    它负责将文本分词 (tokenize)，并将作者名 (string) 转换为标签 (label index)。\n","    \"\"\"\n","    def __init__(self, df: pd.DataFrame, tokenizer, author2id: Dict[str,int], max_len: int = 512):\n","        self.df = df.reset_index(drop=True)\n","        self.tokenizer = tokenizer\n","        self.author2id = author2id  # 从 \"user_a\" -> 0\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        enc = self.tokenizer(\n","            str(row[\"text\"]),\n","            truncation=True,\n","            max_length=self.max_len,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\"\n","        )\n","        item = {k: v.squeeze(0) for k, v in enc.items()}\n","\n","        # --- 开集 (Open-set) 处理 ---\n","        # 检查作者是否为 \"已知\" 作者\n","        author = row.get(\"author\", None)\n","        if pd.isna(author) or author not in self.author2id:\n","            # 如果作者是 \"unknown\" 或不在已知列表中，设置标签为 -1\n","            item[\"labels\"] = torch.tensor(-1, dtype=torch.long)\n","        else:\n","            # 否则，设置标签为对应的 ID (0 到 8)\n","            item[\"labels\"] = torch.tensor(self.author2id[author], dtype=torch.long)\n","\n","        item[\"text\"] = str(row[\"text\"]) # 保留原始文本，用于错误分析\n","        return item\n","\n","class AuthorModel(nn.Module):\n","    \"\"\"\n","    自定义作者归属模型 (与 train.py 一致)\n","    包含一个 BERT 编码器、一个投影层 (用于获取 embedding) 和一个分类器 (用于获取 logits)\n","    \"\"\"\n","    def __init__(self, model_name: str, num_classes: int, emb_dim: int = 256, use_mean_pool: bool = True):\n","        super().__init__()\n","        self.encoder = AutoModel.from_pretrained(model_name)\n","        hidden = self.encoder.config.hidden_size\n","        self.use_mean_pool = use_mean_pool\n","        # 投影层 (Projection Head)，用于将 BERT 输出转换为固定维度的嵌入 (z)\n","        self.proj = nn.Sequential(\n","            nn.Linear(hidden, hidden),\n","            nn.Tanh(),\n","            nn.Linear(hidden, emb_dim)\n","        )\n","        # 分类层 (Classifier Head)，用于从嵌入 (z) 预测作者\n","        self.classifier = nn.Linear(emb_dim, num_classes)\n","\n","    def forward(self, **batch):\n","        labels = batch.pop(\"labels\", None)\n","        # 1. 通过 BERT 编码器\n","        out = self.encoder(**{k:v for k,v in batch.items() if k in (\"input_ids\",\"attention_mask\",\"token_type_ids\")})\n","\n","        # 2. 池化 (Pooling)\n","        if self.use_mean_pool:\n","            last_hidden = out.last_hidden_state\n","            attn_mask = batch[\"attention_mask\"].unsqueeze(-1)\n","            pooled = (last_hidden * attn_mask).sum(1) / attn_mask.sum(1).clamp_min(1e-6)\n","        else:\n","            pooled = out.last_hidden_state[:, 0] # [CLS] token\n","\n","        # 3. 得到嵌入 (z) 和 Logits\n","        z = self.proj(pooled)   # (z) 嵌入向量 (embedding)\n","        logits = self.classifier(z) # (logits) 分类分数\n","\n","        return logits, z, labels\n","\n","# --------------------------\n","# 2. 辅助函数：加载和提取\n","# --------------------------\n","\n","def load_checkpoint(path: str, map_location=\"cpu\"):\n","    ck = torch.load(path, map_location=map_location)\n","    return ck\n","\n","def build_model_from_ck(ckpt: dict, device: str):\n","    \"\"\"从 checkpoint (.pt) 文件中重建模型、分词器和作者列表\"\"\"\n","    authors = ckpt[\"authors\"]\n","    model_name = ckpt.get(\"model_name\", ckpt.get(\"model\", \"bert-base-uncased\"))\n","    use_mean_pool = ckpt.get(\"use_mean_pool\", True)\n","    model = AuthorModel(model_name, num_classes=len(authors), use_mean_pool=use_mean_pool)\n","    model.load_state_dict(ckpt[\"state_dict\"])\n","    model.to(device)\n","    model.eval()\n","    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n","    return model, tokenizer, authors\n","\n","@torch.no_grad()\n","def extract_logits_and_embeddings(model: nn.Module, dataloader: DataLoader, device: str):\n","    \"\"\"\n","    核心函数：遍历数据集，从模型中提取所有的 logits 和 embeddings (z)\n","    \"\"\"\n","    all_logits = []\n","    all_embs = []\n","    all_labels = []\n","    all_texts = []\n","    for batch in tqdm(dataloader, desc=\"Extracting embeddings\"):\n","        texts = batch.pop(\"text\")\n","        labels = batch[\"labels\"].cpu().numpy().tolist()\n","        batch = {k: v.to(device) for k,v in batch.items()}\n","\n","        # 运行模型\n","        logits, z, _ = model(**batch)\n","\n","        all_logits.append(logits.detach().cpu().numpy())\n","        all_embs.append(z.detach().cpu().numpy())\n","        all_labels += labels\n","        all_texts += texts\n","\n","    all_logits = np.concatenate(all_logits, axis=0)\n","    all_embs = np.concatenate(all_embs, axis=0)\n","    return all_logits, all_embs, np.array(all_labels), all_texts"],"metadata":{"id":"_mlOwshRmuW0","executionInfo":{"status":"ok","timestamp":1762355748050,"user_tz":-480,"elapsed":21,"user":{"displayName":"flower","userId":"16750654610954148483"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# -------------------------------------------------------------\n","# 任务 1: 设计开集判别策略 (最大概率阈值、能量分数、原型距离)\n","# -------------------------------------------------------------\n","# 这些函数接收 Logits 或 Embeddings，并为每个样本计算一个“已知度”分数。\n","# “已知度”分数越高 = 越像已知作者 (In-Distribution)\n","# “已知度”分数越低 = 越像未知作者 (Out-of-Distribution)\n","# -------------------------------------------------------------\n","\n","def softmax(x):\n","    e = np.exp(x - np.max(x, axis=1, keepdims=True))\n","    return e / e.sum(axis=1, keepdims=True)\n","\n","def max_probability_score(logits: np.ndarray):\n","    \"\"\"\n","    策略 1: 最大概率 (Max Probability / MSP)\n","    直觉：如果一个样本是“已知”的，模型在某个类别上的置信度会很高。\n","    分数：取 Softmax 概率中的最大值。\n","    \"\"\"\n","    probs = softmax(logits)\n","    return probs.max(axis=1), probs  # 返回 (N,) 的分数 和 (N, C) 的完整概率\n","\n","def energy_score(logits: np.ndarray, T: float = 1.0):\n","    \"\"\"\n","    策略 2: 能量分数 (Energy Score)\n","    直觉：“已知”样本的 logits 能量（通过 logsumexp 计算）通常较低（数值上更负）。\n","    分数：我们返回 -Energy，以便分数越高 = 越“已知”。\n","    \"\"\"\n","    from scipy.special import logsumexp\n","    s = -T * logsumexp(logits / T, axis=1)\n","    return -s # 分数越高越好\n","\n","def prototype_centroids(embeddings: np.ndarray, labels: np.ndarray, authors: List[str]):\n","    \"\"\"\n","    (原型距离的辅助函数)\n","    计算训练集中每个“已知”作者的平均嵌入向量（即“原型”或“质心”）。\n","    \"\"\"\n","    centroids = {}\n","    for i, a in enumerate(authors):\n","        mask = labels == i\n","        if mask.sum() == 0:\n","            centroids[i] = np.zeros(embeddings.shape[1], dtype=float)\n","        else:\n","            centroids[i] = embeddings[mask].mean(axis=0)\n","    return centroids\n","\n","def prototype_distance_score(embeddings: np.ndarray, centroids: Dict[int, np.ndarray], metric: str = \"euclidean\"):\n","    \"\"\"\n","    策略 3: 原型距离 (Prototype Distance)\n","    直觉：“已知”样本的嵌入 (z) 应该靠近其所属类别的“原型”（质心）。\n","    分数：我们计算每个样本到*最近*的那个原型的距离，然后取负值 (-distance)。\n","          因此，距离越近 -> 分数越高 -> 越“已知”。\n","    \"\"\"\n","    from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n","    centroid_matrix = np.stack([centroids[i] for i in sorted(centroids.keys())], axis=0)  # C x D\n","    if metric == \"euclidean\":\n","        d = euclidean_distances(embeddings, centroid_matrix)  # N x C\n","    else:\n","        d = cosine_distances(embeddings, centroid_matrix)\n","    min_d = d.min(axis=1) # 找到到最近原型的距离\n","    return -min_d  # 分数越高越好"],"metadata":{"id":"DVdywHi_my9E","executionInfo":{"status":"ok","timestamp":1762355752613,"user_tz":-480,"elapsed":24,"user":{"displayName":"flower","userId":"16750654610954148483"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# ----------------------------------------------------\n","# 任务 2: 画 ROC / Precision-Recall 曲线, 调 τ (tau)\n","# ----------------------------------------------------\n","\n","def plot_roc_pr(y_true_binary: np.ndarray, score: np.ndarray, out_prefix: str, name: str):\n","    \"\"\"\n","    绘制 ROC 和 PR 曲线，用于评估“开集判别”的好坏。\n","    y_true_binary: 真实标签 (1 = 已知, 0 = 未知)\n","    score:         来自策略 1, 2 或 3 的“已知度”分数\n","    \"\"\"\n","    # y_true_binary: 1 if known (in closed set), 0 if unknown\n","    fpr, tpr, _ = roc_curve(y_true_binary, score)\n","    precision, recall, _ = precision_recall_curve(y_true_binary, score)\n","    roc_auc = auc(fpr, tpr)\n","    pr_auc = auc(recall, precision)\n","\n","    plt.figure()\n","    plt.plot(fpr, tpr, label=f\"ROC AUC={roc_auc:.4f}\")\n","    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC - {name}\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(f\"{out_prefix}_roc_{name}.png\", bbox_inches=\"tight\")\n","    plt.close()\n","\n","    plt.figure()\n","    plt.plot(recall, precision, label=f\"PR AUC={pr_auc:.4f}\")\n","    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"Precision-Recall - {name}\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(f\"{out_prefix}_pr_{name}.png\", bbox_inches=\"tight\")\n","    plt.close()\n","    return roc_auc, pr_auc\n","\n","def tune_threshold_by_f1(y_true_binary: np.ndarray, score: np.ndarray, num_steps: int = 1000):\n","    \"\"\"\n","    调优阈值 (tau):\n","    遍历所有可能的分数阈值，找到那个能最大化 F1 分数 (用于区分 已知/未知) 的阈值。\n","    \"\"\"\n","    best_f1 = -1.0\n","    best_tau = None\n","    thresholds = np.linspace(score.min(), score.max(), num_steps)\n","    for t in thresholds:\n","        # 预测：分数 >= 阈值 -> 预测为\"已知\" (1), 否则为\"未知\" (0)\n","        pred_known = (score >= t).astype(int)\n","        f1 = f1_score(y_true_binary, pred_known)\n","        if f1 > best_f1:\n","            best_f1 = f1\n","            best_tau = t\n","    return best_tau, best_f1"],"metadata":{"id":"HBdFxHXdm03j","executionInfo":{"status":"ok","timestamp":1762355755196,"user_tz":-480,"elapsed":11,"user":{"displayName":"flower","userId":"16750654610954148483"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# ----------------------------------------------------\n","# 任务 3: 做 UMAP/T-SNE 作者嵌入聚类可视化\n","# ----------------------------------------------------\n","# 我们使用从模型中提取的嵌入 (z) 来进行降维和可视化，\n","# 观察“已知”作者是否聚类，“未知”作者是否远离它们。\n","# ----------------------------------------------------\n","\n","def plot_umap(embeddings: np.ndarray, labels: np.ndarray, authors: List[str], out_path: str, n_neighbors: int = 15, min_dist: float = 0.1):\n","    \"\"\"使用 UMAP 进行降维可视化\"\"\"\n","    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=42)\n","    emb2 = reducer.fit_transform(embeddings)\n","    plt.figure(figsize=(8,6))\n","    unique_labels = np.unique(labels)\n","    palette = sns.color_palette(\"hls\", len(unique_labels))\n","    for i, lab in enumerate(unique_labels):\n","        mask = labels == lab\n","        # 如果 lab 是 -1, 标签设为 \"unknown\"\n","        plt.scatter(emb2[mask,0], emb2[mask,1], s=10, label=(authors[lab] if lab>=0 else \"unknown\"), alpha=0.7)\n","    plt.legend(markerscale=2, bbox_to_anchor=(1.05,1), loc='upper left')\n","    plt.title(\"UMAP of embeddings\")\n","    plt.savefig(out_path, bbox_inches=\"tight\")\n","    plt.close()\n","    return emb2\n","\n","def plot_tsne(embeddings: np.ndarray, labels: np.ndarray, authors: List[str], out_path: str, perplexity: int = 30):\n","    \"\"\"使用 t-SNE 进行降维可视化\"\"\"\n","    ts = TSNE(n_components=2, perplexity=perplexity, random_state=42, init='pca')\n","    emb2 = ts.fit_transform(embeddings)\n","    plt.figure(figsize=(8,6))\n","    unique_labels = np.unique(labels)\n","    for i, lab in enumerate(unique_labels):\n","        mask = labels == lab\n","        plt.scatter(emb2[mask,0], emb2[mask,1], s=10, label=(authors[lab] if lab>=0 else \"unknown\"), alpha=0.7)\n","    plt.legend(markerscale=2, bbox_to_anchor=(1.05,1), loc='upper left')\n","    plt.title(\"t-SNE of embeddings\")\n","    plt.savefig(out_path, bbox_inches=\"tight\")\n","    plt.close()\n","    return emb2"],"metadata":{"id":"5uggxsT-m3B7","executionInfo":{"status":"ok","timestamp":1762355757558,"user_tz":-480,"elapsed":7,"user":{"displayName":"flower","userId":"16750654610954148483"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# ----------------------------------------------------\n","# 任务 4: 提取错误案例分析\n","# ----------------------------------------------------\n","# 将模型预测错误 (真值为 A 却预测为 B，或 真值为 A 却预测为 Unknown)\n","# 的样本保存到 CSV 中，以便人工分析。\n","# ----------------------------------------------------\n","\n","def extract_error_cases(texts: List[str], y_true: np.ndarray, y_pred: np.ndarray, probs: np.ndarray,\n","                        emb: np.ndarray, centroid_scores: np.ndarray, out_csv: str, authors: List[str]):\n","    rows = []\n","    for i, (txt, t, p, pr, e, cscore) in enumerate(zip(texts, y_true, y_pred, probs, emb, centroid_scores)):\n","        # y_true (t) 和 y_pred (p) 都是索引 (-1, 0, ... 8)\n","        if t != p: # 只要真实标签和预测标签不一致，就视为错误\n","            pred_label = p if p >= 0 and p < len(authors) else -1\n","            rows.append({\n","                \"idx\": i,\n","                \"text\": txt,\n","                \"true_label\": (authors[t] if t>=0 else \"unknown\"),\n","                \"pred_label\": (authors[pred_label] if pred_label>=0 else \"unknown\"),\n","                \"max_prob\": float(pr.max()),\n","                \"pred_prob\": float(pr[pred_label]) if pred_label>=0 and pred_label < pr.shape[0] else None,\n","                \"centroid_score\": float(cscore),\n","            })\n","    df = pd.DataFrame(rows)\n","    df.to_csv(out_csv, index=False)\n","    return df"],"metadata":{"id":"JPGAvwPdm5_Q","executionInfo":{"status":"ok","timestamp":1762355760379,"user_tz":-480,"elapsed":13,"user":{"displayName":"flower","userId":"16750654610954148483"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# ----------------------------------------------------\n","# 主函数 (Main Pipeline)\n","# ----------------------------------------------------\n","# (已修复 NameError: 'emb' -> 'embs')\n","# (已修复 ValueError: 在 classification_report 中添加 'labels' 参数)\n","# ----------------------------------------------------\n","\n","def main(args):\n","    os.makedirs(args.out_dir, exist_ok=True)\n","    print(\"[Info] Loading checkpoint:\", args.checkpoint)\n","\n","    # --- 检查文件是否存在 ---\n","    if not os.path.exists(args.checkpoint):\n","        print(f\"错误：找不到 Checkpoint 文件: {args.checkpoint}\")\n","        print(\"请上传 'authorship_model.pt' 文件，或修改 '--checkpoint' 路径。\")\n","        return\n","    if not os.path.exists(args.data):\n","        print(f\"错误：找不到 Data 文件: {args.data}\")\n","        print(\"请上传数据文件 (例如 'author_style_dataset_OPENSET.csv')，或修改 '--data' 路径。\")\n","        return\n","    if args.train_data and not os.path.exists(args.train_data):\n","        print(f\"错误：找不到 Train Data 文件: {args.train_data}\")\n","        return\n","    # -------------------------\n","\n","    ck = load_checkpoint(args.checkpoint, map_location=\"cpu\")\n","    model, tokenizer, authors = build_model_from_ck(ck, device=DEVICE)\n","    print(f\"[Info] Loaded model for {len(authors)} authors.\")\n","\n","    # 加载数据集\n","    df = pd.read_csv(args.data)\n","    if \"split\" not in df.columns:\n","        df[\"split\"] = \"test\"\n","    test_df = df[df[\"split\"]==args.split].copy()\n","    print(f\"[Info] Using split {args.split} with {len(test_df)} samples\")\n","\n","    # 构建 Dataloader\n","    author2id = {a:i for i,a in enumerate(authors)}\n","    dataset = AuthorDataset(test_df, tokenizer, author2id, max_len=args.max_len)\n","    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n","\n","    # 1. 提取 Logits 和 Embeddings\n","    logits, embs, labels, texts = extract_logits_and_embeddings(model, loader, DEVICE)\n","\n","    # 2. 【任务 1】计算所有开集策略的分数\n","    scores_maxprob, full_probs = max_probability_score(logits)\n","    scores_energy = energy_score(logits, T=args.energy_T)\n","\n","    # 计算原型（centroids）\n","    if args.train_data is not None:\n","        train_df = pd.read_csv(args.train_data)\n","        train_dataset = AuthorDataset(train_df[train_df[\"split\"]==\"train\"].copy(), tokenizer, author2id, max_len=args.max_len)\n","        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n","        print(\"[Info] Computing centroids from provided train_data...\")\n","        _, emb_train, labels_train, _ = extract_logits_and_embeddings(model, train_loader, DEVICE)\n","        centroids = prototype_centroids(emb_train, labels_train, authors)\n","    else:\n","        print(\"[Warning] No --train_data provided. Computing centroids from *this* split's known labels. (Not recommended for final evaluation)\")\n","\n","        # --- (修复 NameError: 'emb' -> 'embs') ---\n","        centroids = prototype_centroids(embs, labels, authors)\n","        # -----------------------------------------\n","\n","    scores_proto = prototype_distance_score(embs, centroids, metric=args.proto_metric)\n","\n","    # 准备开集判别的真实标签 (1 = 已知, 0 = 未知)\n","    y_true_binary = (labels != -1).astype(int)\n","\n","    # 检查是否有 OOD 样本 (标签为 0 的)\n","    if np.sum(y_true_binary == 0) == 0:\n","        print(\"\\n[Warning] 您的数据集中没有“未知”(unknown)样本 (label = -1)。\")\n","        print(\"           ROC/PR 曲线对于评估“开集”检测将没有意义。\\n\")\n","\n","    # 3. 【任务 2】绘制 ROC/PR 曲线\n","    out_prefix = os.path.join(args.out_dir, args.prefix)\n","    roc_auc_mp, pr_auc_mp = plot_roc_pr(y_true_binary, scores_maxprob, out_prefix, \"maxprob\")\n","    roc_auc_en, pr_auc_en = plot_roc_pr(y_true_binary, scores_energy, out_prefix, \"energy\")\n","    roc_auc_pr, pr_auc_pr = plot_roc_pr(y_true_binary, scores_proto, out_prefix, \"prototype\")\n","\n","    print(\"[Info] AUCs:\")\n","    print(f\"MaxProb ROC={roc_auc_mp:.4f} PR={pr_auc_mp:.4f}\")\n","    print(f\"Energy  ROC={roc_auc_en:.4f} PR={pr_auc_en:.4f}\")\n","    print(f\"Proto   ROC={roc_auc_pr:.4f} PR={pr_auc_pr:.4f}\")\n","\n","    # 调优阈值 (Tau)\n","    if args.tune_threshold:\n","        tau_mp, f1_mp = tune_threshold_by_f1(y_true_binary, scores_maxprob)\n","        tau_en, f1_en = tune_threshold_by_f1(y_true_binary, scores_energy)\n","        tau_pr, f1_pr = tune_threshold_by_f1(y_true_binary, scores_proto)\n","        print(\"[Tuning] best tau (maxprob)=\", tau_mp, \"F1=\", f1_mp)\n","        print(\"[Tuning] best tau (energy)=\", tau_en, \"F1=\", f1_en)\n","        print(\"[Tuning] best tau (proto)=\", tau_pr, \"F1=\", f1_pr)\n","    else:\n","        print(f\"[Info] Using fixed threshold tau = {args.tau}\")\n","        tau_mp = args.tau\n","        tau_en = args.tau\n","        tau_pr = args.tau\n","\n","    # 4. 生成最终的开集预测 (预测为 -1 代表 \"未知\")\n","    pred_labels_closed = np.argmax(logits, axis=1) # 闭集预测\n","    pred_labels_mp = np.where(scores_maxprob >= tau_mp, pred_labels_closed, -1)\n","    pred_labels_en = np.where(scores_energy >= tau_en, pred_labels_closed, -1)\n","    pred_labels_pr = np.where(scores_proto >= tau_pr, pred_labels_closed, -1)\n","\n","    # 5. 【任务 4】保存错误分析 (使用 MaxProb 的结果作为代表)\n","\n","    # 仅在“已知”作者上计算分类报告\n","    mask_known = labels != -1\n","    if mask_known.sum() > 0:\n","\n","        # --- (修复 ValueError: 添加 'labels' 参数) ---\n","        report_mp = classification_report(\n","            labels[mask_known],\n","            pred_labels_mp[mask_known],\n","            labels=list(range(len(authors))),  # 告诉 sklearn 只报告 0-8 类\n","            target_names=authors,\n","            zero_division=0\n","        )\n","        # ---------------------------------------------\n","\n","        print(\"\\n--- Classification Report (MaxProb OpenSet) on Known Authors ---\")\n","        print(report_mp)\n","        with open(os.path.join(args.out_dir, f\"class_report_maxprob.txt\"), \"w\") as f:\n","            f.write(report_mp)\n","    else:\n","        report_mp = \"No known labels present to compute classification report.\"\n","\n","    # 保存错误案例\n","    # df_errors = extract_error_cases(texts, labels, pred_labels_mp, full_probs, embs, scores_proto, os.path.join(args.out_dir, \"error_cases_maxprob.csv\"), authors)\n","    # print(f\"[Info] Saved {len(df_errors)} error cases to {args.out_dir}/error_cases_maxprob.csv\")\n","\n","    # [修改后代码]\n","\n","    # 5. 【任务 4】为所有三种策略保存错误分析\n","    ...\n","    # (计算 classification_report 的代码)\n","    ...\n","    # 保存错误案例\n","    print(\"[Info] Saving error cases for all 3 strategies...\")\n","\n","    # 策略 1: MaxProb\n","    out_csv_mp = os.path.join(args.out_dir, \"error_cases_maxprob.csv\")\n","    df_errors_mp = extract_error_cases(texts, labels, pred_labels_mp, full_probs, embs, scores_proto, out_csv_mp, authors)\n","    print(f\"[Info] Saved {len(df_errors_mp)} error cases (MaxProb) to {out_csv_mp}\")\n","\n","    # 策略 2: Energy\n","    out_csv_en = os.path.join(args.out_dir, \"error_cases_energy.csv\")\n","    df_errors_en = extract_error_cases(texts, labels, pred_labels_en, full_probs, embs, scores_proto, out_csv_en, authors)\n","    print(f\"[Info] Saved {len(df_errors_en)} error cases (Energy) to {out_csv_en}\")\n","\n","    # 策略 3: Prototype\n","    out_csv_pr = os.path.join(args.out_dir, \"error_cases_prototype.csv\")\n","    df_errors_pr = extract_error_cases(texts, labels, pred_labels_pr, full_probs, embs, scores_proto, out_csv_pr, authors)\n","    print(f\"[Info] Saved {len(df_errors_pr)} error cases (Prototype) to {out_csv_pr}\")\n","\n","    # 6. 【任务 3】可视化\n","    umap_path = os.path.join(args.out_dir, \"umap_embeddings.png\")\n","    tsne_path = os.path.join(args.out_dir, \"tsne_embeddings.png\")\n","    print(\"[Info] Generating visualizations...\")\n","    plot_umap(embs, labels, authors, umap_path)\n","    plot_tsne(embs, labels, authors, tsne_path)\n","    print(f\"[Info] Saved UMAP -> {umap_path} and t-SNE -> {tsne_path}\")\n","\n","    # 7. 保存所有分数\n","    out_df = pd.DataFrame({\n","        \"text\": texts,\n","        \"true_label_idx\": labels,\n","        \"pred_closed_idx\": pred_labels_closed,\n","        \"pred_maxprob_idx\": pred_labels_mp,\n","        \"score_maxprob\": scores_maxprob,\n","        \"score_energy\": scores_energy,\n","        \"score_proto\": scores_proto\n","    })\n","    out_df.to_csv(os.path.join(args.out_dir, args.prefix + \"_scores.csv\"), index=False)\n","    print(f\"[Info] Saved scores CSV to {args.out_dir}/{args.prefix + '_scores.csv'}\")\n","\n","    # 8. 保存总结\n","    summary = {\n","        \"aucs\": {\n","            \"maxprob\": {\"roc\": float(roc_auc_mp), \"pr\": float(pr_auc_mp)},\n","            \"energy\": {\"roc\": float(roc_auc_en), \"pr\": float(pr_auc_en)},\n","            \"prototype\": {\"roc\": float(roc_auc_pr), \"pr\": float(pr_auc_pr)}\n","        },\n","        \"best_taus\": {\n","            \"maxprob\": float(tau_mp),\n","            \"energy\": float(tau_en),\n","            \"prototype\": float(tau_pr)\n","        } if args.tune_threshold or args.tau is not None else {}\n","    }\n","    with open(os.path.join(args.out_dir, \"summary.json\"), \"w\") as f:\n","        json.dump(summary, f, indent=2)\n","    print(\"[Done] Analysis complete. Results saved to\", args.out_dir)"],"metadata":{"id":"FuIOVLLsm8LH","executionInfo":{"status":"ok","timestamp":1762355763055,"user_tz":-480,"elapsed":17,"user":{"displayName":"flower","userId":"16750654610954148483"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# # ----------------------------------------------------\n","# # (新) 任务 5: 微调模型头部 (Head Fine-tuning)\n","# # ----------------------------------------------------\n","# #\n","# # 目标：冻结 BERT encoder，只使用“分类损失 + 原型损失”\n","# #      来微调 proj 和 classifier 头部。\n","# #\n","# # ----------------------------------------------------\n","\n","# # [修改后代码] (第 10 行)\n","# from torch.optim import AdamW\n","# import torch.nn.functional as F\n","\n","# # 1. 定义原型/中心损失函数\n","# def compute_prototype_loss(z, labels, device=\"cuda\"):\n","#     \"\"\"\n","#     计算简化的原型/中心损失 (只在批次内计算)\n","#     z: 嵌入 (B, D)\n","#     labels: 标签 (B,)\n","#     \"\"\"\n","#     # 初始化一个标量张量来累积损失\n","#     loss_proto = torch.tensor(0.0, device=device)\n","#     num_classes_in_batch = 0\n","\n","#     # 遍历这个批次中出现的所有唯一类别\n","#     for c in torch.unique(labels):\n","#         # 只为“已知”类别 (c >= 0) 计算簇内距离\n","#         if c.item() == -1:\n","#             continue\n","\n","#         # 找出所有属于类别 'c' 的嵌入\n","#         mask = (labels == c)\n","#         z_class = z[mask]\n","\n","#         # 至少要有2个样本才能计算中心\n","#         if z_class.shape[0] > 1:\n","#             num_classes_in_batch += 1\n","#             # (a) 计算该类的“原型/中心”\n","#             center = z_class.mean(dim=0)\n","\n","#             # (b) 计算该类所有样本到其中心的 L2 距离的平方\n","#             # (z_class - center)^2 -> sum over dim 1 -> mean over batch\n","#             distances_sq = torch.sum((z_class - center.unsqueeze(0))**2, dim=1)\n","\n","#             # 累加该类的平均距离损失\n","#             loss_proto += torch.mean(distances_sq)\n","\n","#     # 返回所有类别的平均损失\n","#     if num_classes_in_batch > 0:\n","#         return loss_proto / num_classes_in_batch\n","#     else:\n","#         return loss_proto # 返回 0.0\n","\n","# # 2. 定义训练一个 Epoch 的函数\n","# def train_epoch(model, dataloader, optimizer, lambda_proto, device):\n","#     model.train() # 切换到训练模式\n","#     total_loss_epoch = 0\n","#     total_loss_ce_epoch = 0\n","#     total_loss_proto_epoch = 0\n","\n","#     # 注意：我们在这里使用 tqdm 来显示进度条\n","#     for batch in tqdm(dataloader, desc=\"Finetune Epoch\"):\n","#         batch.pop(\"text\", None) # 训练时不需要 text\n","#         batch = {k: v.to(device) for k, v in batch.items()}\n","#         labels = batch[\"labels\"]\n","\n","#         # --- 关键：只在“已知”样本上训练 ---\n","#         # 过滤掉标签为 -1 的 \"unknown\" 样本\n","#         known_mask = (labels != -1)\n","#         if known_mask.sum() == 0:\n","#             continue # 如果这个批次全是 unknown，跳过\n","\n","#         labels = labels[known_mask]\n","#         batch = {k: v[known_mask] for k, v in batch.items()}\n","#         # -----------------------------------\n","\n","#         # 1. 前向传播\n","#         logits, z, _ = model(**batch)\n","\n","#         # 2. 计算 Loss 1: 分类损失 (Cross-Entropy)\n","#         loss_ce = nn.CrossEntropyLoss()(logits, labels)\n","\n","#         # 3. 计算 Loss 2: 原型损失\n","#         loss_proto = compute_prototype_loss(z, labels, device)\n","\n","#         # 4. 合并损失 (按 lambda_proto 比例)\n","#         total_loss = loss_ce + (lambda_proto * loss_proto)\n","\n","#         # 5. 反向传播 (只会更新 proj 和 classifier 的权重)\n","#         optimizer.zero_grad()\n","#         total_loss.backward()\n","#         optimizer.step()\n","\n","#         total_loss_epoch += total_loss.item()\n","#         total_loss_ce_epoch += loss_ce.item()\n","#         total_loss_proto_epoch += loss_proto.item()\n","\n","#     N = len(dataloader)\n","#     return total_loss_epoch / N, total_loss_ce_epoch / N, total_loss_proto_epoch / N\n","\n","# # 3. 定义主微调函数\n","# def run_finetune(\n","#     original_ckpt_path=\"./checkpoints/authorship_model.pt\",\n","#     finetuned_ckpt_path=\"./checkpoints/authorship_model_FINETUNED.pt\",\n","#     train_data_path=\"author_style_dataset_OPENSET.csv\",\n","#     num_epochs=5,       # 只需要几个 Epoch\n","#     batch_size=32,\n","#     max_len=512,\n","#     lambda_proto=0.1,   # 超参数：原型损失的权重，您可以调这个\n","#     learning_rate=1e-4  # 头部微调，学习率可以高一点\n","# ):\n","#     print(\"[Info] Starting fine-tuning...\")\n","\n","#     # 1. 加载您原始的、训练好的模型\n","#     ck = load_checkpoint(original_ckpt_path, map_location=\"cpu\")\n","#     model, tokenizer, authors = build_model_from_ck(ck, device=DEVICE)\n","#     print(f\"[Info] Loaded original model from {original_ckpt_path}\")\n","\n","#     # 2. 冻结 ENCODER (这是关键)\n","#     print(\"[Info] Freezing encoder parameters...\")\n","#     for param in model.encoder.parameters():\n","#         param.requires_grad = False\n","\n","#     # 3. 确保头部 (proj, classifier) 是可训练的\n","#     for param in model.proj.parameters():\n","#         param.requires_grad = True\n","#     for param in model.classifier.parameters():\n","#         param.requires_grad = True\n","\n","#     num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","#     num_total = sum(p.numel() for p in model.parameters())\n","#     print(f\"[Info] Trainable params: {num_trainable} / {num_total} ({num_trainable/num_total*100:.2f}%)\")\n","\n","#     # 4. 准备训练数据 (只使用 'train' split)\n","#     df_train = pd.read_csv(train_data_path)\n","#     df_train = df_train[df_train[\"split\"] == \"train\"].copy()\n","\n","#     author2id = {a:i for i,a in enumerate(authors)}\n","#     train_dataset = AuthorDataset(df_train, tokenizer, author2id, max_len=max_len)\n","#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","#     print(f\"[Info] Loaded {len(df_train)} training samples.\")\n","\n","#     # 5. 设置优化器 (!!! 只优化可训练的参数 !!!)\n","#     optimizer = AdamW(\n","#         filter(lambda p: p.requires_grad, model.parameters()),\n","#         lr=learning_rate\n","#     )\n","\n","#     # 6. 训练循环\n","#     print(\"[Info] Starting training loop...\")\n","#     for epoch in range(num_epochs):\n","#         avg_loss, avg_ce, avg_proto = train_epoch(model, train_loader, optimizer, lambda_proto, DEVICE)\n","#         print(f\"Epoch {epoch+1}/{num_epochs} -> \"\n","#               f\"Total Loss: {avg_loss:.4f} (CE: {avg_ce:.4f} + Proto: {avg_proto:.4f})\")\n","\n","#     # 7. 保存微调后的模型\n","#     # 我们更新原始 checkpoint 中的 state_dict\n","#     ck[\"state_dict\"] = model.state_dict()\n","#     ck[\"finetuned_from\"] = original_ckpt_path\n","#     ck[\"finetune_loss\"] = f\"CE + {lambda_proto}*Proto\"\n","\n","#     os.makedirs(os.path.dirname(finetuned_ckpt_path), exist_ok=True)\n","#     torch.save(ck, finetuned_ckpt_path)\n","#     print(f\"[Done] Fine-tuning complete. Model saved to {finetuned_ckpt_path}\")\n","\n","#     # 返回新模型的路径，以便下一步使用\n","#     return finetuned_ckpt_path\n","\n","# # --- 立即执行微调 ---\n","# # (这里我们使用 5 个 Epoch 和 0.1 的 lambda，您可以根据需要调整)\n","# NEW_MODEL_PATH = run_finetune(\n","#     num_epochs=5,\n","#     lambda_proto=0.1,\n","#     learning_rate=1e-4\n","# )"],"metadata":{"id":"XIMjDkRW5evN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ----------------------------------------------------\n","# 运行\n","# ----------------------------------------------------\n","\n","# 1. 定义参数\n","p = argparse.ArgumentParser()\n","p.add_argument(\"--checkpoint\", type=str, default=\"./checkpoints/authorship_model.pt\", help=\"path to checkpoint\")\n","# (修复：指向您上传的 CSV 文件名)\n","p.add_argument(\"--data\", type=str, default=\"author_style_dataset_OPENSET.csv\", help=\"csv dataset with columns [text,author,split]\")\n","# (修复：我们将使用 data 文件中的 'train' split 来计算原型)\n","p.add_argument(\"--train_data\", type=str, default=\"author_style_dataset_OPENSET.csv\", help=\"optionally provide training csv to compute prototypes from train set\")\n","p.add_argument(\"--split\", type=str, default=\"test\", help=\"which split in csv to analyze\")\n","# p.add_argument(\"--out_dir\", type=str, default=\"./open_set_analysis\", help=\"output directory\")\n","p.add_argument(\"--out_dir\", type=str, default=\"./open_set_finetune\", help=\"output directory\")\n","p.add_argument(\"--prefix\", type=str, default=\"run1\", help=\"prefix for output files\")\n","\n","# (修复：移除了重复的 --batch_size)\n","p.add_argument(\"--batch_size\", type=int, default=32)\n","\n","p.add_argument(\"--max_len\", type=int, default=512)\n","p.add_argument(\"--tau\", type=float, default=0.5, help=\"fallback threshold if not tuning\")\n","p.add_argument(\"--tune_threshold\", action=\"store_true\", help=\"search tau by maximizing F1 on known/unknown (requires ground-truth unknown labels)\")\n","p.add_argument(\"--energy_T\", type=float, default=1.0)\n","p.add_argument(\"--proto_metric\", type=str, choices=[\"euclidean\",\"cosine\"], default=\"euclidean\")\n","\n","# 2. (修复：使用 args=[] 来防止 Colab 解析 -f 参数)\n","args = p.parse_args(args=[])\n","\n","# 3. --- 您可以在这里手动覆盖默认值 ---\n","# 例如，如果您想在 'val' split 上调优阈值:\n","# args.split = \"val\"\n","# args.tune_threshold = True\n","\n","# 我们将 --checkpoint 指向刚刚微调过的新模型\n","# ----------------------------------------------------\n","# args.checkpoint = NEW_MODEL_PATH # <--- 这是关键的修改！\n","# [修改后代码]\n","args.checkpoint = \"./checkpoints/authorship_model_FINETUNED.pt\"\n","\n","# 或者，如果您想在 'test' split 上运行 (假设您没有 'unknown' 标签):\n","args.split = \"test\"\n","args.tune_threshold = True # 无法在没有 'unknown' 标签的 test 集上调优\n","# args.tau = 0.5 # 使用一个固定的阈值\n","\n","# (!!重要!!): 您的数据 'author_style_dataset_OPENSET.csv' 的 'test' split\n","# 必须包含 \"unknown\" 作者才能让 tune_threshold=True 工作。\n","# 如果 'test' split 只有已知作者, 请设置 tune_threshold=False。\n","# ------------------------------------\n","\n","# 4. 运行\n","try:\n","    main(args)\n","except FileNotFoundError as e:\n","    print(f\"\\n[Execution Stopped] 关键文件未找到: {e}\")\n","    print(\"请确保在 Colab 中上传了所需的数据集和模型文件，并正确设置了 --checkpoint 和 --data 参数。\")\n","except Exception as e:\n","    print(f\"\\n[Execution Stopped] 发生意外错误: {e}\")\n","    # 打印完整的错误追溯\n","    import traceback\n","    traceback.print_exc()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["36c7b1e4f0c541f6b6f4c53d62195fcc","075dd65d3560482eae295ab5dea1574b","def53e9b690f404892abdea7e7c5db7f","6d889daedf2b49e8879a7c7c361b7fde","84d2c278f204450e935b7152c996f759","bdd27e5aaf334df2a94001e70af9a1c8","25ab19c9eb5f4986972217c16bd209ae","5ccc19bb72104083b1e6426c0ae1b56f","c61ea5dd4b97425cb15e9512e39e8f55","0f6b244405124b0db475645195fd25b7","e7fc93c0aa054f8ea7f13984b8056390","55b786d0367e428ca17fdf35c8404f82","c4aea7fd0d5f4483a7164bedc29c06ee","730247ae3ce74279b1d08f8e10fe209d","87094fbd7e49426d8e66bc6115f20fe3","9d89a156368045bc801602c471a95b18","e44b5e353f834c688db4be4bcaea1cca","b0faf9300cfe44ffaaad5e3b97cc31f8","7d0eab6a57db4d96988b5403f40f7bc7","7aeb345648e34410bf0bbd35c966ea6f","707ce628f2ae4769814404fdcd5b122e","c02894a658de4a86bfc9184e3444f90f","301fbbb772e248438617a76121a2a4a7","45371e99eab54e8aa9ad2dde28ba5484","72067b3fe6a441958c4629202c2a5f4a","63c8ac95f7ee47549e5a5e1a37cd502c","7fc14670185848c9b01cce353a05cf3d","13fc0273e88e4915be5bc48282d8a6d8","e5b32be19f814dde992b767650b8e2c2","95b800bd2ccf4dd480e016c9d0756339","f8337979b4eb40fbbbeedca626aa3720","e3477c7be06c40e98291771874f7217e","da563ee0ac5843c98bfc57601763139f","033e9b17f9d045d1ba878323578824dc","9a049b3e8cd74ee08715dc55041aa5ca","7471ad57a068481db3f50c926d198d1d","6d9c400884f9451ebe297e9d742eb860","e0dbac742b844023894e8967b7b06ac1","868739e3aa804b0c99c6bae6ed7482c3","e04c652574d24609b84ef5c8c22d13a8","6bcaa7dc520f49bea97c1c2382114fcb","b60fcc412dc141b6bdc60e530b969330","dbe54986c9a544daa94763301f30966c","698aa626932a4a398d1ee5c092998b4f","4060425f40bb42099dbcea9c9bbf5c49","c7342787d6cc4fb9918ad490197b9957","037022f881e0485b9004c2707e0d7f30","1add9a35d2784ad8b84fa8a9dcb18346","36c376e1f74440b288373896db0da9f3","b7fad649420e479898b7ab538afcf761","e28c5910c870496284956025a07cfcd9","ef084790e9754569b968c86c77ed3381","da8826d22f664deca028fe6e41fcd8df","5433b88159654d0190235872c691f60e","304e68bfade34dbb8b0f029c6c6ee3a2"]},"id":"-_wJiGF9nQrX","executionInfo":{"status":"ok","timestamp":1762357134464,"user_tz":-480,"elapsed":473780,"user":{"displayName":"flower","userId":"16750654610954148483"}},"outputId":"52d55327-1c93-4f21-cbb1-395ef57235e2"},"execution_count":9,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[Info] Loading checkpoint: ./checkpoints/authorship_model_FINETUNED.pt\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36c7b1e4f0c541f6b6f4c53d62195fcc","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55b786d0367e428ca17fdf35c8404f82","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"301fbbb772e248438617a76121a2a4a7","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"033e9b17f9d045d1ba878323578824dc","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4060425f40bb42099dbcea9c9bbf5c49","version_major":2,"version_minor":0},"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[Info] Loaded model for 9 authors.\n","[Info] Using split test with 2781 samples\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Extracting embeddings: 100%|██████████| 87/87 [06:59<00:00,  4.82s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[Info] Computing centroids from provided train_data...\n"]},{"output_type":"stream","name":"stderr","text":["Extracting embeddings: 100%|██████████| 175/175 [14:12<00:00,  4.87s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Info] AUCs:\n","MaxProb ROC=0.6299 PR=0.6715\n","Energy  ROC=0.6253 PR=0.6675\n","Proto   ROC=0.7322 PR=0.7867\n","[Tuning] best tau (maxprob)= 0.4466705 F1= 0.688034188034188\n","[Tuning] best tau (energy)= 3.5247774 F1= 0.6892411143131604\n","[Tuning] best tau (proto)= -1.5387969 F1= 0.697560975609756\n","\n","--- Classification Report (MaxProb OpenSet) on Known Authors ---\n","                  precision    recall  f1-score   support\n","\n","ArthurConanDoyle       0.54      0.75      0.63       111\n","  CharlesDickens       0.71      0.94      0.81        80\n","      Chesterton       0.99      0.41      0.58       192\n","   EdgarAllanPoe       0.65      0.87      0.74       172\n","  HermanMelville       0.98      0.62      0.76       301\n","      JaneAusten       1.00      0.99      0.99       168\n","       MarkTwain       0.62      1.00      0.77        38\n","      OscarWilde       0.78      1.00      0.87       101\n","   VirginiaWoolf       0.86      0.98      0.92       293\n","\n","       micro avg       0.80      0.80      0.80      1456\n","       macro avg       0.79      0.84      0.79      1456\n","    weighted avg       0.85      0.80      0.79      1456\n","\n","[Info] Saving error cases for all 3 strategies...\n","[Info] Saved 1599 error cases (MaxProb) to ./open_set_finetune/error_cases_maxprob.csv\n","[Info] Saved 1568 error cases (Energy) to ./open_set_finetune/error_cases_energy.csv\n","[Info] Saved 1126 error cases (Prototype) to ./open_set_finetune/error_cases_prototype.csv\n","[Info] Generating visualizations...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["[Info] Saved UMAP -> ./open_set_finetune/umap_embeddings.png and t-SNE -> ./open_set_finetune/tsne_embeddings.png\n","[Info] Saved scores CSV to ./open_set_finetune/run1_scores.csv\n","[Done] Analysis complete. Results saved to ./open_set_finetune\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"09tD6H6QJ6bN"},"execution_count":null,"outputs":[]}]}